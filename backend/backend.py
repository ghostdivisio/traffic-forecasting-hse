# -*- coding: utf-8 -*-
"""backend.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AdJB1IqqTa4b3HoapgfpDyzuQlnoDnS2
"""

import warnings

warnings.filterwarnings("ignore")
import pandas as pd
import numpy as np
import re
from datetime import datetime, date, time
import math
from etna.pipeline import Pipeline
from etna.datasets import TSDataset
from etna.pipeline.pipeline import Pipeline
from etna.models import (
    NaiveModel,
    SeasonalMovingAverageModel,
    CatBoostMultiSegmentModel,
)
from etna.transforms import LagTransform, LinearTrendTransform, LogTransform, MedianOutliersTransform, TimeSeriesImputerTransform, DateFlagsTransform
from etna.transforms import HolidayTransform, StandardScalerTransform, FourierTransform, MeanTransform, TrendTransform, YeoJohnsonTransform
from etna.metrics import MAE, MSE, SMAPE, MAPE
from etna.analysis.outliers import get_anomalies_median, get_anomalies_density
from ruptures.detection import Binseg
from etna.models import CatBoostMultiSegmentModel
from etna.models import SARIMAXModel
from etna.metrics import SMAPE, MAE, MAPE, MSE
from etna.analysis import plot_backtest, plot_trend, plot_forecast, plot_anomalies, plot_change_points_interactive, plot_imputation, plot_feature_relevance
from etna.analysis import plot_periodogram, stl_plot, seasonal_plot, find_change_points, plot_time_series_with_change_points
from etna.analysis import ModelRelevanceTable
from etna.ensembles import VotingEnsemble, StackingEnsemble
from catboost import CatBoostRegressor
from clickhouse_driver import Client
import optuna
from functools import partial
import random
import wandb
from typing import Optional
import typer
from etna.loggers import tslogger, WandbLogger

#Получение датафрейма
def get_data(date, url, source):
    """
    Функция извлекает данные из базы данных на основе заданной даты, URL-адреса и источника и возвращает
    отфильтрованный и сгруппированный кадр данных.
    
    :param date: Дата, с которой должны быть получены данные
    :param url: URL-адрес веб-сайта или веб-страницы, для которой извлекаются данные
    :param source: Параметр источника представляет собой список строк, представляющих источники, из
    которых собираются данные
    :return: Функция `get_data` возвращает отфильтрованный и агрегированный DataFrame, содержащий
    количество уникальных пользователей, которые обращались к определенному URL-адресу из определенного
    источника в указанную дату. Фильтрация выполняется на основе входных параметров «дата», «url» и
    «источник», а возвращаемый кадр данных сортируется по отметке времени («ts»).
    """
    client = Client('big-dw1.hse.ru', 
                user='USER', 
                password='PASSWORD', 
                secure=True, 
                verify=False, 
                database='web_analytics',
                compression=True)
    list_to_str=','.join(source)
    res=re.sub(r',', '|', list_to_str)
    #sql='''SELECT source, url, ts, COUNT(DISTINCT(user_id)) AS users FROM web_analytics.yandex_raw_data WHERE ts >= '%s'AND source='%s' AND url = '%s'
    #GROUP BY ts, url, source ORDER BY ts'''% (date, source, url)
    sql1 = '''SELECT source, url, ts, COUNT(DISTINCT(user_id)) AS users FROM web_analytics.yandex_raw_data 
    WHERE ts >= '%s' AND source REGEXP ('%s') AND match(url, '%s') GROUP BY ts, url, source ORDER BY ts'''% (date, res, url)
    result, columns = client.execute(sql1, with_column_types=True)
    data= pd.DataFrame(result, columns = [tuple[0] for tuple in columns])
    grouped_df=data.groupby(['url', 'ts']).agg({'users': 'sum'}).reset_index()
    #filter_regex='^[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b(?:[-a-zA-Z0-9()@:%_\\+.~#?&\\/=]*)$'
    #pattern=re.compile('(https:/)')
    #filtered = grouped_df[grouped_df['url'].str.contains(filter_regex, flags=re.IGNORECASE, regex=True)]
    #filtered = grouped_df.loc[grouped_df['url'] == pattern]        
    #result=data.loc[data['url'] == '%s'%(url)]#'%s'%(u)
    #return result
    r=grouped_df['url'].tolist()
    for i in r:
        if 'https' in i:
            r[r.index(i)] = 0
    grouped_df['url']=r
    filtered=grouped_df.loc[grouped_df['url'] != 0]   
    return filtered

#Получение ts
def tsdataset(filtered):
    """
    Функция берет отфильтрованный набор данных, преобразует его в набор данных временного ряда,
    группирует его по отметке времени и сегменту и возвращает результирующий набор данных временного
    ряда.
    
    :param filtered: Входные данные, которые необходимо преобразовать в набор данных временного ряда.
    Предполагается, что входные данные имеют столбцы с именами «ts», «users» и «url»
    :return: Функция tsdataset возвращает объект TSDataset.
    """
    filtered["timestamp"] = filtered["ts"]
    filtered["target"] = filtered["users"]
    filtered.drop(columns=["ts", "users"], inplace=True)
    filtered=filtered.rename(columns={'url':'segment'})
    df = TSDataset.to_dataset(filtered)
    ts = TSDataset(df=df, freq="D")
    ts_pandas=ts.to_pandas(ts)
    ts_pandas=ts_pandas.fillna(0)
    r1=ts_pandas['segment'].tolist()
    segmentus=[]
    for i in r1:
        cell=re.match(r'^\w+\.\w+\.\w+', i)
        segmentus.append(cell.group())
    ts_pandas['segment']=segmentus
    frog=pd.DataFrame()
    frog['timestamp']=ts_pandas['timestamp']
    frog['segment']=ts_pandas['segment']
    frog['target']=ts_pandas['target']
    frog1=frog.groupby(['timestamp', 'segment']).agg({'target': 'sum'}).reset_index()
    df = TSDataset.to_dataset(frog1)
    ts = TSDataset(df=df, freq="D")
    return ts, frog1

#новая функция получения tsdataset
def tsdataset_new(filtered, segment):
    """
    Функция принимает отфильтрованный набор данных, преобразует его в набор данных временного ряда и
    группирует его по метке времени и сегменту при суммировании целевой переменной.
    
    :param filtered: Это пандас DataFrame, содержащий данные о трафике веб-сайта со столбцами «ts»
    (отметка времени), «users» (количество пользователей) и «url» (URL-адрес веб-сайта)
    :param segment: Параметр «сегмент» — это строка, представляющая определенный сегмент или комбинацию
    сегментов, по которым пользователь хочет фильтровать набор данных. Если параметр равен None, функция
    возвращает исходный набор данных без какой-либо фильтрации. Если параметр представляет собой строку
    из одного или нескольких сегментов, разделенных символом «|»,
    :return: два объекта: объект TSDataset и объект pandas DataFrame.
    """
    filtered["timestamp"] = filtered["ts"]
    filtered["target"] = filtered["users"]
    filtered.drop(columns=["ts", "users"], inplace=True)
    dataframe=filtered.rename(columns={'url':'segment'})
    df = TSDataset.to_dataset(dataframe)
    ts = TSDataset(df=df, freq="D")
    ts_pandas=ts.to_pandas(ts)
    ts_pandas=ts_pandas.fillna(0)
    r1=ts_pandas['segment'].tolist()
    if segment==None:
        ts_pandas
    else:
        segments=segment.split("|")
        for i in segments:
            if len(segments)==1:
                ts_pandas['segment']=segments[0]        
            else:
                ts_pandas.loc[ts_pandas['segment'].isin(segments)]
    frog=pd.DataFrame()
    frog['timestamp']=ts_pandas['timestamp']
    frog['segment']=ts_pandas['segment']
    frog['target']=ts_pandas['target']
    frog1=frog.groupby(['timestamp', 'segment']).agg({'target': 'sum'}).reset_index()
    df = TSDataset.to_dataset(frog1)
    ts = TSDataset(df=df, freq="D")
    return ts, frog1

#Получение трендов (полином)
def ts_trend(ts, poly_degreee):
    """
    Эта функция строит тренд временного ряда, используя линейную регрессию с заданной полиномиальной
    степенью.
    
    :param ts: Данные временного ряда, для которых мы хотим построить тренд
    :param poly_degreee: poly_степень — это параметр, определяющий степень полинома, используемого в
    преобразовании линейного тренда. Он используется в функции ts_trend для создания двух разных
    преобразований линейного тренда с разными полиномиальными степенями. Результирующие тренды затем
    строятся с помощью функции plot_trend
    :return: Функция ts_trend возвращает график временного ряда ts с двумя линейными линиями тренда
    полиномиальной степени 1 и poly_grade, наложенными поверх него. Функция использует функцию
    `plot_trend` и класс `LinearTrendTransform` для создания графика.
    """
    trends = [
        LinearTrendTransform(in_column="target", poly_degree=1),
        LinearTrendTransform(in_column="target", poly_degree=poly_degreee)
    ]
    return plot_trend(ts, trend_transform=trends)

#Сезонность
def get_seasonality(ts, cycle):
    """
    Эта функция возвращает сезонный график временного ряда с указанным циклом.
    
    :param ts: Данные временного ряда, для которых мы хотим проанализировать сезонность
    :param cycle: Параметр цикла относится к продолжительности сезонного цикла в данных временного ряда.
    Например, если данные временного ряда демонстрируют сезонный характер, который повторяется каждые 12
    месяцев, для параметра цикла будет установлено значение 12
    :return: Функция `get_seasonality` возвращает результат функции `seasonal_plot` с аргументами `ts` и
    `cycle`. Конкретный вывод `seasonal_plot` зависит от реализации этой функции.
    """
    return seasonal_plot(ts=ts, cycle=cycle)

#Аномалии и их устранение
def get_anomalies(ts, window, neighbours, distance):    
    """
    Функция принимает временной ряд, размер окна, количество соседей и коэффициент расстояния и
    возвращает график аномалий, обнаруженных с помощью кластеризации на основе плотности.
    
    :param ts: Данные временных рядов, которые вы хотите проанализировать на наличие аномалий
    :param window: Размер скользящего окна, используемого для расчета плотности временного ряда. Он
    определяет количество точек данных, которые рассматриваются одновременно для обнаружения аномалий
    :param neighbours: Параметр «соседи» относится к количеству соседних точек, которые необходимо
    учитывать при расчете плотности каждой точки во временном ряду. Он используется в функции
    «get_anomalies_density», чтобы определить, какие точки считаются аномалиями
    :param distance: Коэффициент расстояния — это параметр, используемый в алгоритмах обнаружения
    аномалий для определения порога выявления аномалий. Это мера того, насколько далеко точка данных
    должна находиться от остальных данных, чтобы считаться аномалией. Более высокий коэффициент
    расстояния означает, что точки данных должны быть дальше
    :return: график данных временного ряда с выделенными обнаруженными аномалиями. График создается с
    помощью функции plot_anomalies, а аномалии обнаруживаются с помощью функции get_anomalies_density с
    указанными параметрами.
    """
    anomalies=get_anomalies_density(ts, in_column='target', window_size=window, n_neighbors=neighbours, distance_coef=distance)
    pa=plot_anomalies(ts=ts, anomaly_dict=anomalies)
    return pa

def fix_anomalies(ts, window, alpha, strategy, window_outlier):
    """
    Эта функция исправляет аномалии во временном ряду, удаляя выбросы и подставляя отсутствующие
    значения с использованием заданных параметров.
    
    :param ts: Это объект временного ряда, который содержит данные для обработки
    :param window: Параметр окна используется для определения размера скользящего окна, используемого
    для обнаружения и импутации выбросов. Он указывает количество последовательных временных шагов,
    которые следует учитывать за один раз
    :param alpha: Alpha — это параметр, используемый в классе MedianOutliersTransform для определения
    порога обнаружения выбросов. Это значение от 0 до 1, где более высокое значение означает, что
    большее количество точек данных будет считаться выбросами
    :param strategy: Параметр стратегии в функции fix_anomalies относится к стратегии вменения,
    используемой для заполнения пропущенных значений в данных временного ряда. Он может принимать такие
    значения, как «среднее», «медиана», «ffill» (прямое заполнение), «bfill» (обратное заполнение) или
    «междурядье»
    :param window_outlier: Размер окна, используемый для вменения пропущенных значений во временном ряду
    с использованием указанной стратегии
    :return: преобразованные данные временного ряда «ts» после удаления выбросов и вменения
    отсутствующих значений с использованием указанных параметров. Он также возвращает график `pi`
    вмененных значений.
    """
    outliers_remover = MedianOutliersTransform(in_column="target", window_size=window, alpha=alpha)
    ts.fit_transform([outliers_remover])
    outliers_imputer = TimeSeriesImputerTransform(in_column="target", strategy=strategy, window=window_outlier)
    ts.fit_transform([outliers_imputer])
    pi=plot_imputation(imputer=outliers_imputer, ts=ts)
    return ts, pi


 #def backtest(ts, HORIZON, x, x1, N_FOLDS):
    """
    Функция выполняет ретроспективное тестирование временного ряда с использованием модели
    CatBoostMultiSegmentModel с различными преобразованиями и возвращает кадр данных метрик.
    
    :param ts: Данные временного ряда, которые будут использоваться для тестирования модели на
    исторических данных
    :param HORIZON: ГОРИЗОНТ — это параметр, определяющий количество временных шагов для
    прогнозирования. В этом случае он используется в пайплайне для задания горизонта тестирования на
    истории
    :param x: Значение первой задержки, используемой в LagTransform
    :param x1: Параметр x1 — это максимальное значение задержки, используемое в LagTransform. Он
    указывает максимальное количество временных шагов, на которое нужно оглянуться назад при создании
    признаков задержки для целевой переменной
    :return: заголовок кадра данных метрик, сгенерированный функцией тестирования на исторических
    данных.
    """
    model = CatBoostMultiSegmentModel()  
    lags=LagTransform(lags=list(range(x, x1)), in_column="target") 
    holiday_rus = HolidayTransform(iso_code="RUS")
    log = LogTransform(in_column="target")
    scaler=StandardScalerTransform(in_column='target', inplace=True)
    fourier=FourierTransform(period=4.0, order=2)
    dateflags=DateFlagsTransform(day_number_in_week=True, day_number_in_month=True, is_weekend=True, week_number_in_year=True, 
                                 month_number_in_year=True, year_number=True)
    transforms = [log, lags, dateflags, holiday_rus, scaler, fourier]
    pipeline = Pipeline(model=model, transforms=transforms, horizon=HORIZON)
    metrics_df, forecast_df, fold_info_df = pipeline.backtest(
        ts=ts, metrics=[MAE(), MSE(), SMAPE()], n_folds=N_FOLDS, aggregate_metrics=True
    )
    return metrics_df.head(), plot_backtest(forecast_df, ts=ts)

#это уже тоже старая функция бэктеста
#def new_backtest(ts, HORIZON, N_FOLDS, transform_from_front):        
    """
    Функция выполняет ретроспективное тестирование временного ряда с использованием различных
    преобразований и модели CatBoost и возвращает соответствующие показатели и графики.
    
    :param ts: Данные временных рядов, которые будут использоваться для обратного тестирования модели
    :param HORIZON: ГОРИЗОНТ — это количество временных шагов для прогнозирования в будущем
    :param N_FOLDS: N_FOLDS – это количество сгибов, которые следует использовать при перекрестной
    проверке во время тестирования на исторических данных. Он определяет, сколько раз данные будут
    разделены на наборы для обучения и проверки для оценки производительности модели
    :param transform: Параметр «преобразование» представляет собой список преобразований данных, которые
    необходимо применить к данным временных рядов перед их подачей в модель. Эти преобразования могут
    включать отставание, масштабирование, логарифмическое преобразование, преобразование Фурье,
    преобразование тренда, импутирование и многое другое. Конкретные преобразования, которые будут
    применяться, могут быть настроены
    :return: кортеж, содержащий четыре элемента:
    1. График релевантности признаков для данных временных рядов
    2. Фрейм данных, содержащий метрики (MAE, MSE, SMAPE) для каждой складки бэктеста.
    3. График результатов прогноза на истории по сравнению с фактическими данными временного ряда.
    4. Исходные данные временного ряда.
    """
    #start model_fit()
    model = CatBoostMultiSegmentModel()  
    lags_week = LagTransform(in_column="target", lags=list(range(HORIZON, HORIZON+7)), out_column="lags_week")

    scale = StandardScalerTransform(in_column="target")
    log = LogTransform(in_column="target", inplace=True, out_column='log_')
    lags_month = LagTransform(in_column="target", lags=list(range(HORIZON, HORIZON+60)), out_column="lags_month")
    date_flags = DateFlagsTransform(
                day_number_in_week=True,
                day_number_in_month=True,
                is_weekend=True,
                month_number_in_year=True,
                week_number_in_month=True,
                week_number_in_year=True,
                year_number=True,
                special_days_in_week=[5,6],
                out_column="date_flag",
        )
    holidays = HolidayTransform(iso_code="RUS", out_column="holiday")
    holidays_lags  = LagTransform(
                in_column="holiday",
                lags=list(range(3, 8)),
                out_column="holiday_lag",
                )
    four = FourierTransform(period=HORIZON, order=math.ceil(HORIZON/2), out_column="fourier")
    lin_trend = LinearTrendTransform(in_column="target")
    trend_transf = TrendTransform(in_column="target", out_column="trend", change_points_model=None)
    imputer = TimeSeriesImputerTransform(in_column="target", strategy="forward_fill")
    yeoj_transf = YeoJohnsonTransform(in_column="target", inplace=True)
    mean_tr = MeanTransform(in_column="lag_" + str(HORIZON), out_column="mean", window=HORIZON, seasonality=7)

    transforms: list = [imputer, log, scale, four, yeoj_transf, lin_trend, date_flags, holidays, holidays_lags]
    
    #[imputer, scale, four, yeoj_transf, lin_trend, date_flags, holidays, holidays_lags]
    pipeline = Pipeline(model=model, transforms=transforms, horizon=HORIZON)
    pipeline.fit(ts)
    #end

    metrics_df, forecast_df, fold_info_df = pipeline.backtest(
                ts=ts, metrics=[MAE(), MSE(), SMAPE()], n_folds=N_FOLDS, aggregate_metrics=True
                )

    
    ts_features = ts.to_pandas(True)
    ts_features = ts_features.loc[:,~ts_features.columns.str.contains('^time|segment$|targ|four|trend|lags', case=False)]
    model_relevance = CatBoostRegressor(
    cat_features=[*ts_features], verbose=0)
    model_relevance_table = ModelRelevanceTable()

    return model_relevance_table, model_relevance, metrics_df.head(), plot_backtest(forecast_df, ts=ts, history_len=HORIZON)

#СТАРАЯ ФУНКЦИЯ
#def make_prediction(ts, train_start, train_end, test_start, test_end, HORIZON, n_train_samples):
    """
    Функция принимает временной ряд, разбивает его на наборы для обучения и тестирования, применяет
    преобразования и модель CatBoost для составления прогноза и возвращает график прогноза.
    
    :param ts: Данные временных рядов, с которыми мы работаем
    :param train_start: Дата начала периода обучения для данных временных рядов
    :param train_end: `train_end` — это дата окончания периода обучения. Это последняя дата данных
    временного ряда, которые будут использоваться для обучения модели. Любые данные после этой даты
    будут использоваться для тестирования или проверки
    :param test_start: Дата начала периода тестирования для данных временных рядов
    :param test_end: `test_end` — это дата окончания набора тестов. Это последняя дата, для которой у
    нас есть фактические целевые значения и мы хотим сделать прогнозы на будущее
    :param HORIZON: Количество временных шагов для прогнозирования в будущем
    :param n_train_samples: Количество выборок, используемых для обучения модели
    :return: график прогнозируемого временного ряда вместе с фактическим временным рядом теста и
    временным рядом обучения.
    """
    train_ts, test_ts = ts.train_test_split(
        train_start=train_start,
        train_end=train_end,
        test_start=test_start,
        test_end=test_end,
    )
    model=CatBoostMultiSegmentModel()
    lags = LagTransform(in_column="target", lags=[HORIZON, HORIZON+1, HORIZON+2, HORIZON+3, 
                                                HORIZON+4, HORIZON+5, HORIZON+6, HORIZON+7, 
                                                HORIZON+14, HORIZON+21, HORIZON+30])
    log = LogTransform(in_column="target", inplace=False)
    transforms = [log, lags]
    train_ts.fit_transform(transforms)
    model.fit(train_ts)
    future_ts = train_ts.make_future(future_steps=HORIZON, transforms=transforms)
    forecast_ts = model.forecast(future_ts)
    #forecast_ts.inverse_transform(transforms)
    #train_ts.inverse_transform(transforms)
    return plot_forecast(forecast_ts, test_ts, train_ts, n_train_samples=n_train_samples)

def pipeline_train(ts, HORIZON, transform):
    """
    Функция создает конвейер для обучения модели временных рядов с различными преобразованиями и моделью
    CatBoostMultiSegmentModel.
    
    :param ts: Данные временных рядов, которые будут использоваться для обучения конвейера
    :param HORIZON: ГОРИЗОНТ — это параметр, определяющий количество временных шагов для прогнозирования
    в будущем. Он используется в различных преобразованиях, таких как лаг-преобразования и
    преобразования Фурье, для создания функций модели
    :param transform: Параметр `transform` представляет собой список строк, указывающих, какие
    преобразования данных следует применять к данным временных рядов перед обучением модели. Каждая
    строка соответствует определенному преобразованию, такому как масштабирование, логарифмическое
    преобразование, преобразование Фурье и т. д. Функция проверяет, какие преобразования указаны в
    `transform`
    :return: обученный объект конвейера, который включает в себя модель CatBoostMultiSegmentModel и
    список указанных преобразований, который подгоняется к входным данным временных рядов.
    """
    transform1=[]
    model = CatBoostMultiSegmentModel()  
    lags_week = LagTransform(in_column="target", lags=list(range(HORIZON, HORIZON+7)), out_column="lags_week")
    lw='lags_week'
    scale = StandardScalerTransform(in_column="target")
    sc='scale'
    log = LogTransform(in_column="target", inplace=True, out_column='log_')
    lg='log'
    lags_month = LagTransform(in_column="target", lags=list(range(HORIZON, HORIZON+60)), out_column="lags_month")
    lm='lags_month'
    date_flags = DateFlagsTransform(
                            day_number_in_week=True,
                            day_number_in_month=True,
                            is_weekend=True,
                            month_number_in_year=True,
                            week_number_in_month=True,
                            week_number_in_year=True,
                            year_number=True,
                            special_days_in_week=[5,6],
                            out_column="date_flag",
                    )
    d='date_flags'
    holidays = HolidayTransform(iso_code="RUS", out_column="holiday")
    h='holidays'
    holidays_lags  = LagTransform(
                            in_column="holiday",
                            lags=list(range(3, 8)),
                            out_column="holiday_lag",
                            )
    hl='holidays_lags'
    fourier = FourierTransform(period=HORIZON, order=math.ceil(HORIZON/2), out_column="fourier")
    f='fourier'
    lin_trend = LinearTrendTransform(in_column="target")
    lt='lin_trend'
    trend_transf = TrendTransform(in_column="target", out_column="trend", change_points_model=None)
    tt='trend_transf'
    imputer = TimeSeriesImputerTransform(in_column="target", strategy="forward_fill")
    im='imputer'
    yeoj_transf = YeoJohnsonTransform(in_column="target", inplace=True)
    y='yeoj_transf'
    mean_tr = MeanTransform(in_column="lag_" + str(HORIZON), out_column="mean", window=14, seasonality=7)
    m='mean_tr'
    print(transform)
    if y in transform:
        transform1.append(yeoj_transf)
    if m in transform:
        transform.append(mean_tr)
    if im in transform:
        transform1.append(imputer)
    if sc in transform:
        transform1.append(scale)
    if f in transform:
        transform1.append(fourier)
    if lt in transform:
        transform1.append(lin_trend)
    if d in transform:
        transform1.append(date_flags)
    if h in transform:
        transform1.append(holidays)
    if hl in transform:
        transform1.append(holidays_lags)
    if lw in transform:
        transform1.append(lags_week)
    if lg in transform:
        transform1.append(log)
    if lm in transform:
        transform1.append(lags_month)

    transforms1=list(set(transform1))
    transforms: list = transforms1
    pipeline = Pipeline(model=model, transforms=transforms, horizon=HORIZON)
                    #ts.fit_transform(transforms)
    pipeline.fit(ts)
    return pipeline, transforms

def backtest(ts, pipeline, N_FOLDS):    
    """
    Функция выполняет ретроспективное тестирование временного ряда с использованием заданного конвейера
    и возвращает релевантность функций, метрики и график прогноза.
    
    :param ts: Данные временного ряда, которые будут использоваться для обратного тестирования конвейера
    :param pipeline: Конвейер — это объект, который содержит необходимые шаги для предварительной
    обработки данных временных рядов, обучения модели машинного обучения и прогнозирования новых данных.
    Он используется в функции ретроспективного тестирования для оценки производительности модели на
    исторических данных
    :param N_FOLDS: N_FOLDS – это количество сгибов, которые следует использовать при перекрестной
    проверке во время тестирования на исторических данных. Это гиперпараметр, который определяет,
    сколько раз модель будет обучаться и тестироваться на разных подмножествах данных
    :return: три значения: график релевантности функций, фрейм данных метрик и график бэктест-прогноза.
    """
    metrics_df, forecast_df, fold_info_df = pipeline.backtest(
                        ts=ts, metrics=[MAE(), MSE(), SMAPE()], n_folds=N_FOLDS, aggregate_metrics=True
                        )
    ts_features = ts.to_pandas(True)
    ts_features = ts_features.loc[:,~ts_features.columns.str.contains('^time|segment$|targ|four|trend|lags', case=False)]
    model_relevance = CatBoostRegressor(
    cat_features=[*ts_features], verbose=0)
    model_relevance_table = ModelRelevanceTable()
    return model_relevance, model_relevance_table, metrics_df.head(), forecast_df

#НОВАЯ ФУНКЦИЯ ПРОГНОЗА
def make_forecast(pipeline, n_train_samples, ts, HORIZON):
    """
    Эта функция создает прогноз с использованием заданного конвейера и отображает его вместе с
    обучающими данными.
    
    :param pipeline: Конвейер — это модель машинного обучения, которая была обучена на исторических
    данных временных рядов и используется для прогнозирования будущих значений временных рядов
    :param n_train_samples: n_train_samples — количество выборок, используемых для обучения модели
    прогнозирования. Он используется для построения данных обучения вместе с прогнозируемыми данными для
    сравнения
    :param ts: ts — это объект временного ряда, представляющий исторические данные, используемые для
    обучения модели прогнозирования. Он содержит значения временного ряда в разные моменты времени
    :return: вывод функции plot_forecast, который представляет собой график прогнозируемого временного
    ряда (forecast_ts), а также исходный временной ряд обучения (train_ts) и количество обучающих
    выборок (n_train_samples).
    """
    forecast = pipeline.forecast()
    target_users=ts.to_pandas(forecast)
    users1=target_users['target'].tail(HORIZON).sum()
    yu=(f'Прогноз на {HORIZON} дней по пользователям сайта равен {math.ceil(users1)} пользователей')
    return plot_forecast(forecast_ts=forecast, train_ts=ts, n_train_samples=n_train_samples), yu, HORIZON

def tune_parametres(HORIZON, transforms, ts):
    def init_logger(config: dict, project: str = "wandb-sweeps", tags: Optional[list] = ["test", "sweeps"]):
        tslogger.loggers = []
        wblogger = WandbLogger(project=project, tags=tags, config=config)
        tslogger.add(wblogger)

    def set_seed(seed):
        random.seed(seed)
        np.random.seed(seed)
    def objective(trial: optuna.Trial, metric_name: str, ts: TSDataset, horizon: int = HORIZON, lags: int = 24, seed: int = 42):
        set_seed(seed)
        pipeline = Pipeline(
            model=CatBoostMultiSegmentModel(
                iterations=trial.suggest_int("iterations", 10, 100),
                depth=trial.suggest_int("depth", 1, 12),
                                    ),
            transforms=transforms,
            horizon=HORIZON,
                )
        init_logger(pipeline.to_dict())
        metrics, _, _ = pipeline.backtest(ts=ts, metrics=[SMAPE()])
        return metrics[metric_name].mean()
    #@st.cache_data
    def run_optuna(horizon: int, metric_name: str = "SMAPE", storage: str = None, study_name: Optional[str] = None, 
                   n_trials: int = 5, direction: str = "minimize", freq: str = "D", lags: int = 24, seed: int = 11, transforms=transforms):

        study = optuna.create_study(
                storage=storage,
                study_name=study_name,
                sampler=optuna.samplers.TPESampler(multivariate=True, group=True),
                load_if_exists=True,
                direction=direction)

                # Run Optuna optimization
        study.optimize(partial(objective, metric_name=metric_name, ts=ts, horizon=horizon, lags=lags, seed=seed), n_trials=n_trials, n_jobs=1)
                
        return study.best_params
    optuna_params = run_optuna(horizon=14, transforms=transforms)
    model = CatBoostMultiSegmentModel(iterations=optuna_params['iterations'], depth=optuna_params['depth'])
    return model

def backtest_tuned(ts, model, N_FOLDS): 
    metrics_df1, forecast_df1, fold_info_df1 = model.backtest(
                        ts=ts, metrics=[SMAPE()], n_folds=N_FOLDS, aggregate_metrics=True
                        )
    ts_features1 = ts.to_pandas(True)
    ts_features1 = ts_features1.loc[:,~ts_features1.columns.str.contains('^time|segment$|targ|four|trend|lags', case=False)]
    model_relevance = CatBoostRegressor(
    cat_features=[*ts_features1], verbose=0)
    model_relevance_table = ModelRelevanceTable()
    return metrics_df1.head()

def new_prediction(model, n_train_samples, ts, HORIZON):
    forecast1 = model.forecast()
    target_users1=ts.to_pandas(forecast1)
    users2=target_users1['target'].tail(HORIZON).sum()
    yu1=(f'Прогноз на {HORIZON} дней по пользователям сайта равен {math.ceil(users2)} пользователей')
    return plot_forecast(forecast_ts=forecast1, train_ts=ts, n_train_samples=n_train_samples), yu1


